---
toc: true
layout: post
description: Classification evaluation matrices, part-1
categories: [Machine Learning]
comments: true
title: ক্লাসিফিকেশন ইভ্যালুয়েশন মেট্রিসেস(Classification evaluation matrices) [পর্ব - ১]
---
আমরা মেশিন লার্নিং এর বিভিন্ন এল্গোরিদম ব্যবহার করে, বিভিন্ন ধরনের সমস্যা সমাধানের চেষ্টা করি। তার মধ্যে ক্লাসিফিকেশন নিয়ে সম্ভবত আমরা সবচেয়ে বেশি কাজ করে থাকি। কিভাবে এই এল্গোরিদমগুলোকে মূল্যায়ন করা যায় তার কিছু পদ্ধতি দেখে নিবো। নতুবা বুঝবো কিভাবে কোন নির্দিষ্ট কাজের জন্য আমার কোন এল্গোরিদম ব্যবহার করা উচিত?

### ক্লাসিফিকেশন একুরেসি(Classification Accuracy)

একুরেসি শব্দটা যখন আমরা ব্যবহার করি তখন আমরা আসলে এই ক্লাসিফিকেশন একুরেসিকেই বুঝিয়ে থাকি। ছোটবেলা থেকে যেধরনের হিসেব করে আমরা অভ্যস্ত এটা ঠিক সেরকম কিছুই। কোন জটিল, মারপ্যাঁচ নেই।

 $$\text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Total number of predictions made}}$$

 অর্থাৎ, আমাকে যদি ১০০ টা প্রেডিকশন করতে হয় যার - মধ্যে ৯০ টা সঠিকভাবে করতে পারি আর বাকি ১০ টা ভুল করি। তবে, উপরের সূত্রমতে আমার ক্লাসিফিকেশন একুরেসি আসবে ৯০%( $$ \frac{৯০}{১০০} $$) ।

এই পদ্ধতি, একটা মডেল কতটা ভালোভাবে প্রেডিক্ট করতে পারছে কিংবা তার কার্যকারিতা সম্পর্কে জানার জন্য যথেষ্ট নয়। ধরি, Kaggle এর বিখ্যাত [টাইটানিক কম্পিটেশনের](https://www.kaggle.com/c/titanic) জন্য তৈরি একটি মডেলের ক্লাসিফিকেশন একুরেসি ভ্যালিডেশন(validation) স্টেজে পেলাম ৯৮% - তাহলে কি সেটা দারুন কোন মডেল? যদি খেয়াল করে দেখি সে সবসময়ই "1" প্রেডিক্ট করছে (অর্থাৎ যাত্রী বেঁচে গিয়ে ছিল। '0' দ্বারা দূর্ঘটনায় মৃতদের বোঝায়।),যে ডাটা দিয়ে মডেলকে প্রেডিক্ট করতে বলা হচ্ছে সেখানে ১০০ টার মধ্যে ৯৮ টাই বেঁচে যাওয়া মানুষের ডাটা ছিল। যেটার জন্য আসলে "মেশিন লার্নিং"-ই প্রয়োজন নেই, শুধু "print" সেটেটমেন্ট দিয়ে "1" প্রিন্ট করে দিলেই হয় যাবে। কিন্তু সেটা কি টেস্ট ফাইলে কাজ করবে? সেখানে এই মডেল মুখ থুবড়ে পড়ে থাকবে।

### কনফিউশন মেট্রিক্স(Confusion Matrix)

কোন মডেল কতটুকু ভালোভাবে প্রেডিক্ট করতে পারছে তা জানা ও বুঝার জন্য এই মেট্রিক্স খুবই গুরুত্বপূর্ণ। আমরা কোন একটা বাইনারি ক্লাসিফিকেশন প্রবলেমের কথা চিন্তা করি। [ব্রেস্ট ক্যান্সার ডাটাসেটের](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) সাথে সবারই কমবেশি পরিচয় থাকার কথা। যে ডাটাসেট ইউজ করে কারো ব্রেস্ট ক্যান্সার শনাক্ত করতে পারি। যেহেতু এখানে সম্ভাব্য আউটপুট তথা ক্লাস(ব্রেস্ট ক্যান্সার আছে, ব্রেস্ট ক্যান্সার নেই) দু'টি তাই এটিকে বাইনারি ক্লাসিফিকেশন প্রবলেম বলা হচ্ছে।

এখানে মডেলের ভুলটা আমরা কিভাবে চিন্তা করতে পারি? আমার মডেল বলছে যার ক্যান্সার আছে, সেক্ষেত্রে দু'টো সম্ভাবনা থাকে - তার আসলেই ক্যান্সার আছে, নয়তো ক্যান্সার না থাকার পরও আমার মডেল বলছে তার ক্যান্সার আছে।

আর যার ক্যান্সার নেই সেক্ষেত্রেও এমন ভুল হতে পারে যে, তাকে বলছে তার ক্যান্সার আছে। এভাবে আমরা মোট ৪ টা সিনারিও পাই -

![_config.yml]({{ site.baseurl }}/images/confusion_matrix.png)

ছবির Predicted - YES/NO আমার মডেলের উত্তর, আর Actual YES/NO আমার কাছে যে ডাটা আছে সেটার উত্তর(বাস্তব)।

**True Positive** - বলতে বুঝায় আমার মডেল বলছে রোগীর ব্রেস্ট ক্যান্সার আছে এবং বাস্তবেও(ডাটাসেটেও) দেখা যাচ্ছে তার ক্যান্সার আছে। সুতরাং, যখন প্রেডিক্টেড পজেটিভ রেজাল্ট আর বাস্তবের পজেটিভ রেজাল্ট মিলে যায় সেটা।

**False Negative** - যখন আমার মডেল বলছে রোগীর ব্রেস্ট ক্যান্সার হয় নি কিন্তু বাস্তবে তার ক্যান্সার আছে। সুতরাং, যখন প্রেডিক্টেড রেজাল্ট নেগেটিভ কিন্তু বাস্তবের রেজাল্ট পজেটিভ থাকে।

**False Positive** - যখন আমার মডেল বলছে রোগীর ক্যান্সার আছে কিন্তু বাস্তবে রোগীর ক্যান্সার নেই। সুতরাং, প্রেডিক্টেড রেজাল্ট পজেটিভ কিন্তু বাস্তবের রেজাল্ট নেগেটিভ।

**True Negative** - যখন আমার মডেল বলছে রোগীর ক্যান্সার নেই এবং বাস্তবেও রোগীর ক্যান্সার নেই। সুতরাং, প্রেডিক্টেড রেজাল্ট নেগেটিভ এবং বাস্তবের রেজাল্টও নেগেটিভ।

আমরা যে উপরে ক্লাসিফিকেশন একুরেসি বের করেছি সেখানে -

$$ \text{Number of correct predictions} = \text{True Positive +  True Negative} $$

আমরা এখন মডেলের পার্ফর্মেন্স আরেকটু ভালোভাবে বুঝতে কিছু প্রশ্ন করতে পারি। আমাদের মডেল যাদের ক্যান্সার রোগীকে শনাক্ত করছে সেটা কতটুকু বিশ্বাসযোগ্য?

### প্রেসিশন(Precision)

প্রেসিশন(Precision) আমাদের উপরের প্রশ্নের উত্তর দিবে -

$$ \text{Precision} = \frac{\text{True Positive}}{\text{True Positive + False Positive}} $$

এর মান কম আসলে বুঝতে পারবো আমাদের মডেল ক্যান্সার রোগীকে সঠিকভাবে শনাক্ত করতে পারছে না বরং যাদের ক্যান্সার নেই তাদের ক্যান্সার রোগী হিসেবে শনাক্ত করছে। উদাহরণ দিয়ে যদি বুঝতে চেষ্টা করি -

True Positive(TP) = 1

False Positive(FP) = 2

$$Precision = \frac{TP}{TP + FP} = \frac{1}{1 + 2} = 0.33$$

সুতরাং, আমার মডেল যদি ১০০ জন ক্যান্সার রোগী শনাক্ত করে তবে তার মধ্যে কেবল ৩৩ জন প্রকৃতপক্ষে ক্যান্সার রোগী।

### রিকল(Recall)

এখন প্রশ্ন যদি হয় - আমাদের মডেল প্রকৃতপক্ষে কত ক্যান্সার রোগীকে শনাক্ত করতে পেরেছে?

এই প্রশ্নের উত্তর রিকল(Recall) থেকে পাবো আমরা।

$$\text{Recall} = \frac{\text{True Positive}}{\text{True Positive + False Negative}} $$

এখন আমরা ছোট একটা উদাহরণ দিয়ে বুঝে নিই -

True Positive(TP) = 1

False Negative(FN) = 9

$$Recall =  \frac{TP}{TP + FN} = \frac{1}{1 + 9} = 0.1$$

এর মানে দাঁড়াচ্ছে, মোট ১০ জন ক্যান্সার রোগীর মধ্যে সে ১ জনকে সঠিকভাবে শনাক্ত করতে পেরেছে।

#### Update-1 on September 14th

### এফ ওয়ান স্কোর(F1 Score)

প্রেসিশন এবং রিকল দুইটা আলাদা প্রশ্নের উত্তর দেয়। কিন্তু আমার মডেলকে ঠিকভাবে মূল্যায়নের জন্য আসলে এদের যেকোন একজনকে নয় বরং উভয়কেই প্রয়োজন। দুইটার মধ্যে একটা সামঞ্জস্য করে কিছু করতে পারলে আমাদের জন্য মঙ্গল। সেই কাজের দায়িত্ব নেয় - এফ ওয়ান স্কোর(F1 score)। একে "এফ স্কোর"(F score) অথবা "এফ মেজার"(F measure)-ও বলা হয়ে থাকে। সমীকরণের মাধ্যমে যদি আমরা দেখতে চাই -

$$ F1 = 2 * \frac{1}{\frac{1}{precision} + \frac{1}{recall}} = 2 * \frac{precision * recall}{precision + recall} $$

প্রেসিশন এবং রিকল-কে ধরে  এরিথমেটিক মিন(arithmetic mean) বের করা হয় নি। কারণ দুইটার হর(denominator) আলাদা। চাইলেই দু'টি সংখ্যার গড় বের করা সম্ভব - যোগ করে, ২ দিয়ে ভাগ দিয়ে। কিন্তু তাতে কি আদৌ কোন অর্থবহ মানে বের করা সম্ভব হবে?

যার জন্য প্রেসিশন আর রিকলের হার্মোনিক মিন([Harmonic mean](https://www.mathsisfun.com/numbers/harmonic-mean.html)) বের করা হয়। আর এই গড়কে "এফ ওয়ান স্কোর"(F1 Score) বলে। এর মানের রেঞ্জ [০,১]

#### Resources

1 - [Metrics To Evaluate Machine Learning Algorithms in Python](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)

2 - [Metrics to Evaluate your Machine Learning Algorithm](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234)

3 - [Classification: True vs. False and Positive vs. Negative](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)
