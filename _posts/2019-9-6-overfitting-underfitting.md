---
toc: true
layout: post
description: Understanding underfitting and overfitting in ML
categories: [Machine Learning]
comments: true
title: ওভারফিটিং, আন্ডারফিটিং [মেশিন লার্নিং টুকিটাকি]
---

অগা-মগা-বগা তিন ঘনিষ্ট বন্ধু। ওয়াহিদ স্যার ওদের ক্লাসের গণিতের শিক্ষক। এর আগের বছরও ওয়াহিদ স্যারকে ওরা গণিত ক্লাসে পেয়েছিল। স্যারের ক্লাসের ধরনের সাথে ওরা বেশ পরিচিতই। স্যার ক্লাসে যেগুলো করায় ঐগুলোই আবার বাড়ির কাজ হিসেবে দেয়। আর প্রতি চ্যাপ্টারে যেই অনুশীলনি থাকে সেগুলো থেকে ক্লাস টেস্টের প্রশ্ন করে। গাইড বই এর সাহায্য নিয়ে অনুশীলনিগুলো খুব সহজেই করা সম্ভব।

ওরা তিন বন্ধুই এইসব জানে, কিন্তু বগার পড়াশোনায় কোন মন নেই। আর গণিত সে একেবারেই পছন্দ করে না। তাই সে ক্লাসে স্যার যখন পড়ায় তখন খাতায় তা তুলে নেয় না, বাড়ির কাজও করে নিয়ে আসে না। তাই ক্লাস-টেস্টেও খারাপ করে।
আর মগা খুব মনোযোগী ছাত্র, সে স্যারের বলা প্রতিটা কথা পর্যন্ত খাতায় তুলে, সব কাজ ঠিক ঠাক করে। তাই মগা ক্লাস-টেস্টেও ফুল মার্ক পায়।

বাকি থাকে অগা, যে কি-না সব বুঝে বুঝে করতে বধ্য-পরিকর। না বুঝে একটা অংকও সে করতে রাজী না। স্যারের কথা মনোযোগ দিয়ে শুনে, কোন লাইনের পরে কোন লাইন কেন লিখা হচ্ছে তা চিন্তা করে। বাড়ির কাজ পুরো শেষ করতে না পারলেও যতোটুকু করে নিজে বুঝে বুঝে করে। ক্লাস-টেস্টে মগার মতো ফুল-মার্ক না পেলেও খারাপ করে না।

এভাবেই তারা ছয় মাস পাড় করে দিলো, এবার সামনে প্রথম সাময়িক পরীক্ষা। স্কুলের নতুন নিয়ম অনুযায়ী পরীক্ষার প্রশ্ন সব গণিত শিক্ষকের কাছ থেকে নিয়ে সম্মিলিতভাবে করা হবে।
পরীক্ষা ভালো মতো হলো, পরীক্ষা শেষের কয়েকদিন পরই পরীক্ষার খাতা দেয়া হলো। কি মনে হয় কে কেমন করলো এই তিন বন্ধুর মধ্যে?

বগা যে খারাপ করবে তা সবাই বুঝতেই পারছি। মূল প্রশ্নটা হলো – অগা আর মগা কি করলো?
মগা বেশ খারাপ করেছে, তার মতো ক্লাসের সব কিছুতে ফুল মার্ক পাওয়া একজন ছাত্র কি-না গণিতে ৬০ পেলো। আর অগা কি-না পেলো ৮৫। এর কারণ পরীক্ষার প্রশ্নে বেশকিছু অংক অন্য বই থেকে নেয়া হয়েছিল। যদিও টপিক এক থাকলেও প্রশ্ন কমন পড়ে নি তাই মগা আর সেই প্রশ্নের উত্তরই দিতে পারে নি। আর অগা বুঝে বুঝে পড়েছে বিধায় নতুন প্রশ্ন তার জন্য কোন সমস্যা ছিল না, সে তো বুঝে বুঝেই উত্তর করেছে যতোটুকু পেরেছে।

এবার ফিরে আসি যা বুঝাতে এই গল্পের আবির্ভাব।
বগার অবস্থাটাকে মেশিন লার্নিং-এ underfitting বলে, মগার অবস্থাকে overfitting এবং অগার অবস্থাটাকে মেশিন লার্নিং এর আদর্শ অবস্থা বলা চলে।

এখন আরেকটু টেকনিকালভাবে বিষয়গুলো বুঝতে চেষ্টা করি –
মেশিন লার্নিং এর বিভিন্ন স্টেপের মধ্যে একটি স্টেপ হলো – মডেল সিলেকশন। কোন মডেল নিয়ে আমি এগুতে চাই সেটা নির্ধারণ করা। কি দেখে এই সিলেকশনটা করা হয় তা একটু জেনে নিই।

আমাদের কাছে নির্দিষ্ট পরিমাণ ডাটা থাকে যা দিয়ে আমাদের কাজ করতে হয়। যেটা ডাটাসেট নামেই বেশি পরিচিত। এই নির্দিষ্ট সংখ্যক ডাটাসেটের ডাটা পয়েন্ট নিয়েই আমাকে যা করার তা করতে হবে। খুব আদর্শ ধরা হয় – ৬০% ডাটা দিয়ে মডেল ট্রেইন করা, ২০% দিয়ে ক্রস-ভ্যালিডেশন করা আর বাকি ২০% দিয়ে মডেল টেস্ট করা। আমরা মূলত এখন ট্রেইন এর ৬০% আর cross-validation এর ২০% নিয়ে কথা বলবো।

বোঝার সুবিধার্থে ধরি, আমাদের ডাটাসেটে মোট ১০০টা ডাটা পয়েন্ট আছে। যার ৬০ টা দিয়ে আমি ট্রেইন করাবো, আর ২০ টা দিয়ে ক্রস-ভ্যালিডেশন করবো।
m = training set size = 60
আর দুইটা মডেল ধরি, model1 এবং model2.

আমরা প্রথমে মডেলকে ১ টি ডাটা পয়েন্ট দিয়ে ট্রেইন করবো, এরপর ক্রস ভ্যালিডেশনে তার পার্ফরমেন্স দেখবো। এরপর ২-টি ডাটা পয়েন্ট দিয়ে, ৩-টি দিয়ে, এভাবে ৬০-টি ডাটা পয়েন্ট দিয়ে আমরা মডেলকে ট্রেইন করবো। আমরা এখানে মূলত আমাদের ডাটাসেটে মডেল কি ধরনের আচরন করে তা দেখতে চাচ্ছি, যার জন্য এভাবে ভেঙ্গে ভেঙ্গে কাজ করছি।
ট্রেইনিং এর পরে উক্ত মডেল কতটা ভালোভাবে কাজ করছে তা দেখার জন্য ক্রস ভ্যালিডেশন ব্যবহার করা হয়। সেই আলাদা করে রাখা ২০ টা ডাটা পয়েন্ট। এর মধ্যে কতটা সঠিক উত্তর দিতে পারছে আর কতটা ভুল সেটার শতকরা প্রকাশ হলো cv_error।

এখানে খেয়াল করার বিষয় আমরা ট্রেইন করার জন্য ধীর ধীরে ডাটা পয়েন্ট বাড়াচ্ছি কিন্তু ক্রস ভ্যালিডেশনের সাইজ সবসময় ফিক্সড থাকবে যা কি-না ২০।

এখন মেশিন লার্নিং এর ক্ষেত্রে আমরা কি করি কিংবা কি চাই? আমরা মেশিনকে কিছু একটা শিখিয়ে পরবর্তীতে দেখতে চাই সে কতটুকু শিখলো? কতটুকু ঠিকভাবে সে প্রেডিক্ট করতে পারছে। আমরা শতকরা হিসেবে তা প্রকাশ করে থাকি। ৮৫% একুরেসি মানে ১০০ বারের মধ্যে সে ৮৫ বার সঠিক উত্তর দিচ্ছে আর বাকি ১৫ বার ভুল উত্তর দিচ্ছে।
আমরা এখন তার এই ভুল করার ব্যাপারটা গ্রাফের মাধ্যমে দেখি সাথে দুইটা নতুন টার্মস এর সাথেও পরিচিত হবো(bias and variance)।
Model1 এর ক্ষেত্রে নিম্নোক্ত গ্রাফটি পাই –

![_config.yml]({{ site.baseurl }}/images/underfit.jpg)

এই ধরনের গ্রাফকে লার্নিং কার্ভ বলা হয়। ট্রেইনিং ডাটা এর ক্ষেত্রে মডেল যে ইরোর দেয় সেটা training_error এবং cross validation এর সময় যে ইরোর দেয় সেটা cv_error. X – axis রিপ্রেজেন্ট করছে যে পরিমাণ ডাটা দিয়ে আমি আমার মডেলকে ট্রেইন করছি তা(১ – ৬০ পর্যন্ত যে ধীরে ধীরে যাচ্ছি) এবং Y-axis রিপ্রেজেন্ট করছে ইরোরের পরিমাণকে(কতটুকু ভুল করছে)।

Model1 এর ক্ষেত্রে যতো বেশি ডাটা দিয়ে ট্রেইন করছি ততো বেশি ইরোর পাচ্ছি এবং cv_error আগের থেকে কমলেও ট্রেইনিং ইরোরের খুব কাছে। তার মানে দুই-ক্ষেত্রেই অনেক বেশি ইরোর দিচ্ছে। গল্পের বগার মতো ক্লাসেও খারাপ করছে আবার পরীক্ষাতেও খারাপ করছে। training_error এর উঠতি মানকে High Bias বলা হয়।
Model2 এর ক্ষেত্রে নিম্নোক্ত গ্রাফটি পাই –

![_config.yml]({{ site.baseurl }}/images/overfit.jpg)

এখানে দেখতে পাচ্ছি training_error এর তুলনায় cv_error যথেষ্ট বেশি। যা বুঝাচ্ছে মগার মতো ক্লাসে খুবই ভালো রেজাল্ট করছে কিন্তু নতুন কোন প্রশ্ন একটু ঘুরিয়ে দিলেই আর পারছে না। এইখানে আরেকটা বিষয় লক্ষ্য করার তা হলো দুইটা ইরোরের মধ্যবর্তী ফাঁকা জায়গাটা, যা বেশ অসামঞ্জস্যপূর্ণ। cv_error এর মান training_error এর তুলনায় এতো বেশি হওয়াকে High Variance বলা বলা হয়।

Bias-Variance Trade-off বলে একটা কথা আছে, যার মাধ্যমে আমরা মডেল সিলেক্ট করে থাকি। Low bias যেখানে থাকবে সেখানে high variance থাকবে এবং যেখানে High bias থাকবে সেখানে Low Variance থাকবে। সবসময় চেষ্টা করা হয় যথাসম্ভব low bias রেখে variance ও low রাখার। কিন্তু দুইটাকেই একত্রে কমিয়ে রাখা সম্ভব না। এসবক্ষেত্রে একটু ছাড় দিয়ে এগুতে হয়। অনেকটা অগা-এর মতো, সব পড়ে সে শেষ করতে পারতো না। কিন্তু যা পড়তো বুঝে বুঝে পড়তো, পরীক্ষায় কিন্তু সে ১০০ পায় নি কিন্তু যথেষ্ট ভালো পেয়েছিল(৮৫)।

৬ থেকে ৭ টা মডেলের মধ্য থেকে যদি আমাকে একটা বাছাই করতে হয়, তখন আমি সেটাকেই বাছাই করবো যার লার্নিং কার্ভ দেখে বুঝতে পারবো সেখানে overfitting কিংবা underfitting এর সম্ভাবনা যথাসম্ভব কম। ভালো মডেলটাই তো টেস্ট সেটে ভালো উত্তর দিতে পারবে, তখনই কেবল তাকে দিয়ে কাজ করানো সম্ভব বাস্তব জগতে।

[ লিখায় কোন ভুল-ত্রুটি থাকলে মন্তব্যে তা ধরিয়ে দিবেন আশা করি। ধন্যবাদ ]
